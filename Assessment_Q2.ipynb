{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Some initial imports, do **NOT** write any new code here:"
      ],
      "metadata": {
        "id": "b8Tbn1kZlxAa"
      },
      "id": "b8Tbn1kZlxAa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8bbc7bc",
      "metadata": {
        "id": "f8bbc7bc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import hf_hub_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc740a9",
      "metadata": {
        "id": "bbc740a9"
      },
      "outputs": [],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "from plotly import graph_objs as go\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from torchvision.transforms import Normalize\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from IPython.display import display, clear_output\n",
        "from collections import Counter\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a1a2216",
      "metadata": {
        "id": "9a1a2216"
      },
      "source": [
        "# Question 2: ECG Beat Classification and Anomaly Detection\n",
        "\n",
        "Electrocardiography (ECG) records the electrical activity of the heart over time using electrodes placed on the skin. ECG signals are widely used in clinical practice for detecting arrhythmias, monitoring cardiac function, and guiding diagnosis and treatment. Automated analysis of ECG signals is therefore an important application area for deep learning, with direct implications for screening, triage, and decision support.\n",
        "\n",
        "In this question, you will work with a cleaned ECG dataset. The dataset contains **197 records** drawn from **three arrhythmia databases**. All signals have been resampled to **128 Hz**, and each recording is approximately **30 minutes** in duration. Each record is stored as a Python dictionary with the following fields:\n",
        "\n",
        "- `patient_id`: an anonymised identifier for the patient from whom the recording was obtained.  \n",
        "- `source_db`: the originating database for this record.  \n",
        "- `sampling_rate`: the sampling frequency of the signal in Hz (128 for this cleaned dataset).  \n",
        "- `signal`: a one-dimensional array containing the ECG time series.  \n",
        "- `beat_locs`: an array of sample indices marking the onset of each annotated heartbeat in the signal.  \n",
        "- `beat_labels`: an array of integer labels associated with each beat location.\n",
        "\n",
        "Beat labels in this assessment have been mapped to a simplified index space from **0** to **4**, where **0** denotes normal beats, **1** and **2** correspond to different abnormality subclasses (supra ventricular ectopic (SVEB) and ventricular ectopic beats (VEB)), and **3** represents unknown or other beats. The exact mapping between indices and the original clinical annotation classes is provided in the accompanying file `class_mapping.json`. You should refer to this file when interpreting the label distribution and when designing your models.\n",
        "\n",
        "This question is divided into three parts:\n",
        "\n",
        "- **Part 2.A – Exploratory Data Analysis and Tooling**: you will perform basic exploration of the ECG signals and annotations, and construct simple plotting and preprocessing utilities to support the later tasks.  \n",
        "- **Part 2.B – Classification and Anomaly Detection**: you will build a supervised deep learning model for beat-level classification, using the simplified label scheme, and explicitly examine its behaviour for normal versus abnormal beats.  \n",
        "- **Part 2.C – Discussion**: you will critically discuss your modelling choices, results, limitations, and potential improvements, in a concise written analysis guided by the prompts.\n",
        "\n",
        "You should approach these parts progressively: insights and tools developed in Part 2.A are expected to inform and support your solutions in Parts 2.B and 2.C.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "The next few blocks of code provided in the notebook will download the dataset, load the ECG records into memory, and import the accompanying class–mapping file required for interpreting the beat labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4963c1d",
      "metadata": {
        "id": "d4963c1d"
      },
      "outputs": [],
      "source": [
        "# Use this snippet to download the dataset\n",
        "dataset = load_dataset(\"dpelacani/ecg-led2-cleaned\")\n",
        "\n",
        "# download class_mapping.json\n",
        "mapping_path = hf_hub_download(\n",
        "    repo_id=\"dpelacani/ecg-led2-cleaned\",\n",
        "    filename=\"class_mapping.json\",\n",
        "    repo_type=\"dataset\"\n",
        ")\n",
        "\n",
        "# load it\n",
        "with open(mapping_path, \"r\") as f:\n",
        "    idx_to_class = json.load(f)\n",
        "\n",
        "print(dataset, idx_to_class)  # print dataset and mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f672f61",
      "metadata": {
        "id": "7f672f61"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## 2.A) Exploratory Data Analysis and Pre-processing\n",
        "\n",
        "The goal of this part is to carry out a set of simple exploratory checks on the ECG dataset and to prepare the beat-level representation that will be used in later tasks. Two helper functions are provided:\n",
        "\n",
        "- **`plot_signal`**: plots a segment of the ECG signal together with its annotated beat locations and labels.  \n",
        "- **`split_by_beat`**: takes a full ECG recording and returns a list of individual beat segments based on the annotated beat locations.\n",
        "\n",
        "Using these tools, you must complete the following:\n",
        "\n",
        "1. **Visualise the data**  \n",
        "   Use `plot_signal` to visualise a **subset of 50 consecutive beats** for **five different patients**, ensuring that beat locations and labels are annotated in the plot. These examples should give you an intuitive sense of how the signals vary across patients and beat types.\n",
        "\n",
        "2. **Construct the beat-level dataset**  \n",
        "   Use `split_by_beat` to compile a dataset where **each beat is one sample**. Build two aligned arrays/lists:\n",
        "   - one containing the beat waveforms: `list[(floats)]`\n",
        "   - one containing the corresponding beat labels (0–4) `list[(int)]`\n",
        "\n",
        "3. **Apply a simple pre-processing filter**  \n",
        "   Exclude beats whose durations fall outside physiologically plausible ranges. Specifically, keep only beats whose lengths fall between:  \n",
        "   - **minimum length** corresponding to a **maximum heart rate of 240 bpm** (32 samples)  \n",
        "   - **maximum length** corresponding to a **minimum heart rate of 30 bpm** (256 samples)  \n",
        "   \n",
        "   Beats outside this range should be removed, as they likely reflect annotation errors or segmentation issues.\n",
        "\n",
        "4. **Plot summary statistics**  \n",
        "   After filtering, produce two histograms:\n",
        "   - one showing the **distribution of beat lengths**,  \n",
        "   - one showing the **distribution of beat classes** (0–4).  \n",
        "\n",
        "These steps should give you a clear initial understanding of the dataset and will provide the structured inputs required for the classification task in Part 2.B.\n",
        "\n",
        "<br>\n",
        "\n",
        "Here are the helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f89a3c9",
      "metadata": {
        "id": "4f89a3c9"
      },
      "outputs": [],
      "source": [
        "def plot_signal(\n",
        "        signal,\n",
        "        title=\"ECG Signal\",\n",
        "        sampling_rate=128,\n",
        "        beat_locations=None,\n",
        "        beat_annotations=None,\n",
        "        ax = None,\n",
        "\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Plots an ECG signal with optional anomalous beat annotations.\n",
        "    Parameters:\n",
        "        signal (np.ndarray): The ECG signal to plot.\n",
        "        title (str): The title of the plot.\n",
        "        sampling_rate (int): The sampling rate of the signal in Hz.\n",
        "        beat_locations (list or np.ndarray): Indices of beat locations in the signal.\n",
        "        beat_annotations (list): Annotations corresponding to the beat locations.\n",
        "        ax (matplotlib.axes.Axes): Optional matplotlib axes to plot on.\n",
        "    \"\"\"\n",
        "    if ax is None:\n",
        "        _, ax = plt.subplots(figsize=(20, 5))\n",
        "\n",
        "    time = np.arange(len(signal)) / sampling_rate / 60.\n",
        "    ax.plot(time, signal)\n",
        "\n",
        "    if beat_locations is not None:\n",
        "        ax.scatter(beat_locations / sampling_rate / 60., signal[beat_locations], color='red', label='BEAT', marker='o')\n",
        "        if beat_annotations is not None:\n",
        "            for loc, ann in zip(beat_locations, beat_annotations):\n",
        "                if ann != 'NOR':\n",
        "                    ax.text(loc / sampling_rate / 60. + 0.05*np.max(time), signal[loc] + 0.05, ann, color='red', fontsize=8, weight='bold')\n",
        "\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Time (min)\")\n",
        "    ax.set_ylabel(\"Normalised Amplitude\")\n",
        "    ax.set_ylim([-0.5, 1])\n",
        "    ax.grid()\n",
        "\n",
        "    if ax is None:\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b94b3d",
      "metadata": {
        "id": "86b94b3d"
      },
      "outputs": [],
      "source": [
        "def split_by_beat(signal, beat_locs):\n",
        "    \"\"\"\n",
        "    Splits the ECG signal into individual beats based on beat locations.\n",
        "    Parameters:\n",
        "        signal (np.ndarray): The ECG signal to split.\n",
        "        beat_locs (list or np.ndarray): Indices of beat locations in the signal.\n",
        "    Returns:\n",
        "        list: A list of individual beats extracted from the signal.\"\"\"\n",
        "    beats = []\n",
        "    starts = [0] + beat_locs.tolist()[:-1]\n",
        "    ends = beat_locs.tolist() + [len(signal)]\n",
        "    for start, end in zip(starts, ends):\n",
        "        beats.append(signal[start:end])\n",
        "    return beats"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "Write your answer to this question below. You can use as many code and text blocks as needed.\n",
        "\n",
        "Please, **make sure to thoroughly describe and comment every piece of code that you include in your answer**. You will be expected to understand every line of code that you write.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "XRnOJ6O3nQiG"
      },
      "id": "XRnOJ6O3nQiG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Visualise the data**"
      ],
      "metadata": {
        "id": "JkzUZnmnKtD6"
      },
      "id": "JkzUZnmnKtD6"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_dataset = dataset[\"train\"]\n",
        "df = train_dataset.to_pandas()\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "id": "YIhiMWbTzbLW"
      },
      "id": "YIhiMWbTzbLW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12be7df1",
      "metadata": {
        "id": "12be7df1"
      },
      "outputs": [],
      "source": [
        "# As dataset is a DatasetDict, access the train split\n",
        "train_dataset = dataset[\"train\"]\n",
        "\n",
        "# select 5 patiends\n",
        "for i in range(5):\n",
        "    record = train_dataset[i]\n",
        "    signal = np.array(record[\"signal\"], dtype=float)\n",
        "    beat_locs = np.array(record[\"beat_locs\"], dtype=int)\n",
        "    beat_labels = record[\"beat_labels\"]\n",
        "\n",
        "    # select first 50 beats\n",
        "    K = min(50, len(beat_locs))\n",
        "    beat_locs_50 = beat_locs[:K]\n",
        "    beat_labels_50 = beat_labels[:K]\n",
        "\n",
        "    # Crop signal\n",
        "    start = int(beat_locs_50[0])\n",
        "    end   = int(beat_locs_50[-1])\n",
        "    signal_crop = signal[start:end]\n",
        "\n",
        "    # Convert tor relative index and ensure its int\n",
        "    beat_locs_rel = (beat_locs_50 - start).astype(int)\n",
        "\n",
        "    # Limit the relative index within the fragment range\n",
        "    beat_locs_rel = beat_locs_rel[(beat_locs_rel >= 0) & (beat_locs_rel < len(signal_crop))]\n",
        "\n",
        "    # Slice the annotation to ensure the length consistency\n",
        "    beat_annotations = [idx_to_class[str(lbl)] for lbl in beat_labels_50[:len(beat_locs_rel)]]\n",
        "\n",
        "    plot_signal(\n",
        "        signal=signal_crop,\n",
        "        beat_locations=beat_locs_rel,\n",
        "        beat_annotations=beat_annotations,\n",
        "        title=f\"Patient {i+1} – First {len(beat_locs_rel)} Beats (cropped)\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "2. **Construct the beat-level dataset**"
      ],
      "metadata": {
        "id": "xnwOvS_5Kw9v"
      },
      "id": "xnwOvS_5Kw9v"
    },
    {
      "cell_type": "code",
      "source": [
        "all_beats = []\n",
        "all_labels = []\n",
        "\n",
        "# iterate over all recordings\n",
        "for record in train_dataset:\n",
        "\n",
        "    signal = np.array(record[\"signal\"], dtype=float)\n",
        "    beat_locs = np.array(record[\"beat_locs\"])\n",
        "    beat_labels = np.array(record[\"beat_labels\"], dtype=int)\n",
        "\n",
        "    # split into individual beats\n",
        "    beats = split_by_beat(signal, beat_locs)\n",
        "\n",
        "    # extend lists\n",
        "    all_beats.extend(beats)\n",
        "    all_labels.extend(beat_labels)\n",
        "\n",
        "len(all_beats), len(all_labels)\n"
      ],
      "metadata": {
        "id": "7_r7a894KyN4"
      },
      "id": "7_r7a894KyN4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "3. **Apply a simple pre-processing filter**  "
      ],
      "metadata": {
        "id": "4igPkBEoK00n"
      },
      "id": "4igPkBEoK00n"
    },
    {
      "cell_type": "code",
      "source": [
        "# 32 samples = 0.25 seconds (240 bpm)\n",
        "# 256 samples = 2.0 seconds (30 bpm)\n",
        "max_heart_rate = 240\n",
        "min_heart_rate = 60\n",
        "sample_rate = 128\n",
        "min_len = (60/max_heart_rate) * sample_rate # shortest allowed beat\n",
        "max_len = (256/min_heart_rate) * sample_rate # longest allowed beat\n",
        "\n",
        "filtered_beats = []\n",
        "filtered_labels = []\n",
        "\n",
        "for beat, lbl in zip(all_beats, all_labels):\n",
        "    if min_len <= len(beat) <= max_len:\n",
        "        filtered_beats.append(beat)\n",
        "        filtered_labels.append(lbl)\n",
        "\n",
        "print(\"Original beats:\", len(all_beats))\n",
        "print(\"Filtered beats:\", len(filtered_beats))\n"
      ],
      "metadata": {
        "id": "a10SBWisK4QV"
      },
      "id": "a10SBWisK4QV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "4. **Plot summary statistics**"
      ],
      "metadata": {
        "id": "P1cAKkvNK4iN"
      },
      "id": "P1cAKkvNK4iN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram: beat lengths\n",
        "beat_lengths = [len(b) for b in filtered_beats]\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.hist(beat_lengths, bins=40)\n",
        "plt.title(\"Distribution of Beat Lengths (after filtering)\")\n",
        "plt.xlabel(\"Beat Length (# samples)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Histogram: label classes\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(filtered_labels, bins=np.arange(0,7)-0.5, rwidth=0.8)\n",
        "plt.xticks([0,1,2,3,4])\n",
        "plt.title(\"Distribution of Beat Classes\")\n",
        "plt.xlabel(\"Beat Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L_eMLKB5K6Dd"
      },
      "id": "L_eMLKB5K6Dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FINAL SUMMARY\")\n",
        "print(\"Total beats extracted:\", len(all_beats))\n",
        "print(\"Beats after filtering:\", len(filtered_beats))\n",
        "print(\"Class distribution:\", Counter(filtered_labels))"
      ],
      "metadata": {
        "id": "_7ZAj3O81Yxe"
      },
      "id": "_7ZAj3O81Yxe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "00fc5918",
      "metadata": {
        "id": "00fc5918"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## 2.B) Classification and Anomaly Detection\n",
        "\n",
        "In this part you will build a supervised **beat-level classifier** using the segmented beats prepared in Part 2.A. Each beat is treated as an individual sample with a label in the simplified index space (0–4). Key points to consider:\n",
        "\n",
        "- You should drop all beats with a label of **3** and only train the classifier for labels **0**, **1** and **2**. This will make the training easier, given the significant class imbalance.\n",
        "\n",
        "- Beats naturally vary in duration, so you must decide how to convert them into a consistent representation suitable for a model. You are free to choose any reasonable approach; at the simplest level, you may choose to zero-pad beats to a fixed length, but more refined strategies are also acceptable.\n",
        "\n",
        "- You are expected to design the full solution **yourself**: the model, the preprocessing pipeline, the train/validation splits, and the overall training procedure. You must also decide on **suitable evaluation metrics** for this problem.\n",
        "\n",
        "- As established in Part 2.A, the dataset is **heavily imbalanced**, with normal beats dominating the distribution. This affects both training and evaluation: models that ignore imbalance tend to overfit normal beats while failing on minority abnormal classes. **Strong solutions will address imbalance explicitly and will aim to produce models that perform reliably across all classes, not only the majority one.** You are, therefore, required to report each validation metric twice: one for normal (0) and one for abnormal (1-2), separately.\n",
        "\n",
        "- Only include code that is necessary to reproduce your results. Notebook organisation and clarity form part of the assessment (see the main *README*).\n",
        "\n",
        "- You should ensure that the notebook clearly displays how your chosen **evaluation metric(s) evolve over training iterations or epochs.**\n",
        "\n",
        "- You may include **up to two** solutions in this notebook, in recognition that partially working attempts may still receive marks under the criteria outlined in the *README*, but you are encouraged to start with a simple, reliable baseline before attempting a more complex model.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "Write your answer to this question below. You can use as many code and text blocks as needed.\n",
        "\n",
        "Please, **make sure to thoroughly describe and comment every piece of code that you include in your answer**. You will be expected to understand every line of code that you write.\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c4929e",
      "metadata": {
        "id": "66c4929e"
      },
      "outputs": [],
      "source": [
        "# drop all beats with a label of 3\n",
        "clean_beats = []\n",
        "clean_labels = []\n",
        "\n",
        "for beat, lbl in zip(filtered_beats, filtered_labels):\n",
        "    if lbl != 3:\n",
        "        clean_beats.append(beat)\n",
        "        clean_labels.append(lbl)\n",
        "\n",
        "clean_beats = np.array(clean_beats, dtype=object)  # safe for variable-length beats\n",
        "clean_labels = np.array(clean_labels)\n",
        "\n",
        "print(\"Total beats without label 3:\", len(clean_beats))\n",
        "print(\"Class counts:\", Counter(clean_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zero-pad to a fixed length\n",
        "fixed_len = max_len # use the max length obtained from Part 2.A\n",
        "\n",
        "def pad_beat(beat, length=int(fixed_len)):\n",
        "    arr = np.zeros(length, dtype=np.float32)\n",
        "    L = min(len(beat), length)\n",
        "    arr[:L] = beat[:L]\n",
        "    # Case A: len(beat) shorter, copy all elements and remain left zeros\n",
        "    # Case B: len(beat) longer, truncate to max_length\n",
        "    # here is explained by AI\n",
        "    return arr\n",
        "\n",
        "X = np.stack([pad_beat(b) for b in clean_beats])\n",
        "y = clean_labels.astype(int)\n",
        "\n",
        "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n"
      ],
      "metadata": {
        "id": "bdbN5_zI8fF2"
      },
      "id": "bdbN5_zI8fF2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train/validation split\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "train_idx, val_idx = next(sss.split(X, y))\n",
        "\n",
        "X_train, X_val = X[train_idx], X[val_idx]\n",
        "y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "print(\"Train size:\", len(X_train), \"Val size:\", len(X_val))\n"
      ],
      "metadata": {
        "id": "qou9av58_t7u"
      },
      "id": "qou9av58_t7u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "metadata": {
        "id": "XVDs44-fAYHu"
      },
      "id": "XVDs44-fAYHu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "class BeatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # (1, L) for CNN\n",
        "        return self.X[i].unsqueeze(0), self.y[i]\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    BeatDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    BeatDataset(X_val, y_val), batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "YeU0VOxjBIAp"
      },
      "id": "YeU0VOxjBIAp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Classifier\n",
        "class CNNBeatClassifier(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool1d(2),\n",
        "\n",
        "            torch.nn.Conv1d(16, 32, kernel_size=5, padding=2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool1d(2),\n",
        "\n",
        "            torch.nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = torch.nn.Linear(64, 3)  # labels: 0,1,2\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        x = x.squeeze(-1)\n",
        "        return self.fc(x)\n",
        "\n",
        "model = CNNBeatClassifier()\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "JaxieSzJA0pA"
      },
      "id": "JaxieSzJA0pA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train and valid\n",
        "def train(model, optimizer, criterion, train_loader):\n",
        "  model.train()\n",
        "  train_loss = 0\n",
        "  for xb, yb in train_loader:\n",
        "      xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      preds = model(xb)\n",
        "      loss = criterion(preds, yb)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "\n",
        "  train_loss /= len(train_loader)\n",
        "  return train_loss\n",
        "\n",
        "def valid(model, optimizer, criterion, train_loader):\n",
        "  model.eval()\n",
        "  val_loss = 0\n",
        "  all_preds = []\n",
        "  all_true = []\n",
        "  with torch.no_grad():\n",
        "      for xb, yb in val_loader:\n",
        "          xb, yb = xb.to(device), yb.to(device)\n",
        "          preds = model(xb)\n",
        "          loss = criterion(preds, yb)\n",
        "          val_loss += loss.item()\n",
        "\n",
        "          # all_preds.append(preds)\n",
        "          # all_true.append(yb)\n",
        "      val_loss /= len(val_loader)\n",
        "      return val_loss\n",
        "      #  all_preds, all_true\n"
      ],
      "metadata": {
        "id": "FOpg7M1CDRZA"
      },
      "id": "FOpg7M1CDRZA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize hyperparamters\n",
        "lr = 1e-3\n",
        "batch_size = 32\n",
        "nepochs = 100\n",
        "wd = 1e-6\n"
      ],
      "metadata": {
        "id": "Dck-gC02Dnuq"
      },
      "id": "Dck-gC02Dnuq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class_counts = Counter(y_train)\n",
        "total = sum(class_counts.values())\n",
        "weights = torch.tensor([total/class_counts[c] for c in sorted(class_counts.keys())], dtype=torch.float32)\n",
        "# the count for each actual class labels\n",
        "weights = weights.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr, weight_decay=wd)\n"
      ],
      "metadata": {
        "id": "WRUgA29DHKN5"
      },
      "id": "WRUgA29DHKN5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to store loss values\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(nepochs):\n",
        "    train_loss = train(model, optimizer, criterion, train_loader)\n",
        "    val_loss = valid(model, optimizer, criterion, val_loader)\n",
        "\n",
        "    # Unpack if returned as tuple\n",
        "    if isinstance(train_loss, tuple):\n",
        "        train_loss = train_loss[0]\n",
        "    if isinstance(val_loss, tuple):\n",
        "        val_loss = val_loss[0]\n",
        "\n",
        "    # Convert to float explicitly\n",
        "    train_losses.append(float(train_loss))\n",
        "    val_losses.append(float(val_loss))\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, nepochs+1), train_losses, label='Train Loss', marker='o')\n",
        "plt.plot(range(1, nepochs+1), val_losses, label='Validation Loss', marker='s')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Lnah8LB8Bsdx"
      },
      "id": "Lnah8LB8Bsdx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kO9Rm430_svM"
      },
      "id": "kO9Rm430_svM"
    },
    {
      "cell_type": "markdown",
      "id": "8b7b78d3",
      "metadata": {
        "id": "8b7b78d3"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "## 2.C) Discussion (max 250 words)\n",
        "\n",
        "Reflect critically on your solution to Part 2.B. In your discussion, address the following points:\n",
        "\n",
        "1. **Modelling choices**\n",
        "\n",
        "   Explain the main decisions behind your model design(s) and why you believe these choices are suitable for this task.\n",
        "\n",
        "2. **Performance and validation**\n",
        "   \n",
        "   Interpret your model’s performance on normal versus abnormal beats using the evaluation metrics you selected. Comment on how class imbalance affected the results and what strategies you have sought to mitigate its impact.\n",
        "\n",
        "3. **Limitations and improvements**\n",
        "   \n",
        "   Identify the main limitations of your approach and outline specific steps that could meaningfully improve performance. You may refer to architectural changes, alternative representations, different imbalance-handling strategies, or improved validation schemes.\n",
        "\n",
        "Your answer should be technically focused, directly address these points, and remain within the stated word limit. Overly long or off-topic discussions will be penalised.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling choices  \n",
        "Referred to AI recommendations, 1D CNN and LSTM models are commonly used for ECG dataset. Here I chose 1D CNN as it's fast and best morphology learning.\n",
        "\n",
        "1D CNN architecture with three convolutional layers and  adaptive pooling to capture temporal patterns in beat waveforms. This design balances expressive power with computational efficiency, making it well-suited for variable-length ECG-like signals. The final linear layer outputs logits for three classes, aligning with the clean_label set [0,1,2].\n",
        "\n",
        "# Performance\n",
        "Training and validation loss curves show steady convergence, though validation loss fluctuates after 20 epochs, suggesting mild overfitting.\n",
        "\n",
        "Class imbalance was evident: normal beats dominated the dataset, while abnormal beats were underrepresented. To mitigate this, I applied inverse-frequency class weighting in the `CrossEntropyLoss`, ensuring the model penalized misclassification of rare classes more heavily. Stratified splitting preserved class proportions across train and validation sets, supporting fair evaluation, which is also suggested by AI.\n",
        "\n",
        "# Limitations\n",
        "The model’s performance on abnormal beats remains limited, likely due to insufficient representation and subtle waveform differences. Future improvements could include:\n",
        "- augmenting minority class samples via jittering or time warping;\n",
        "- fine-tuning features for better CNN performance;\n",
        "- implementing k-fold cross-validation for more robust generalization estimates.\n",
        "- Incorporating domain-specific features could enhance discriminative power.\n"
      ],
      "metadata": {
        "id": "cBEsjTAMmOhh"
      },
      "id": "cBEsjTAMmOhh"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}